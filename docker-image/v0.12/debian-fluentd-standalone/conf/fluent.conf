
@include systemd.conf
@include kubernetes.conf

## We use the concat plugin to handle multiline logs.
## We specify the regex of the starting of every OneData log, and concat next logs
## until we match the regex which means that we start a new log.
<filter **>                               
  @type concat                            
  key log                                 
  multiline_start_regexp /^\[(op|oz)_(worker|panel)\] (\[\w )?\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}.\d{3}/                                                                 
  flush_interval 5                        
  timeout_label @NORMAL                   
</filter>

## We can use the rewrite_tag_filter plugin to categorize logs
## We match regex patterns to the logs, and if it matches we
## change the tag to include a category (ex: datastore, erlang, monitoring, ...)
## it is commented out for performance testing.
## We also use the relabel plugin to mark as @NORMAL logs that were timed out by the concat plugin (logs that are not multiline)
#<match kubernetes.**>
#  @type relabel
#  @label @NORMAL
#  @type rewrite_tag_filter
#  rewriterule1 log dddaz\@changes\_worker od.datastore.${tag}
#  rewriterule2 log CRASH\sREPORT od.erlang.${tag}
#  rewriterule3 log Supervisor\scouchbeam od.datastore.${tag}
#  rewriterule4 log gen\_server od.erlang.${tag}
#  rewriterule5 log monitoring od.monitoring.${tag}
#  rewriterule6 log DBSync od.dbsync.${tag}
#  rewriterule7 log .+ od.untagged.${tag}
#</match>

## As the code just over is commented out,
## we rewrite the relabel plugin. (see up for comment "We also use the relabel plugin...")
<match **>
  @type relabel
  @label @NORMAL
</match>

<label @NORMAL>
##<match od.*>

## This filter is used with the rewrite_tag_filter, it allows to extract
## a part of the tag to put it in a new field (od_service).
#<filter od.**>
#  @type record_transformer
##  enable_ruby true
#  <record>
#    od_service ${tag_parts[1]}
#  </record>
#</filter>

## We match all logs starting with kubernetes.**, if we changed tags with the rewrite_tag_filter,
## we need to change the match parameters with "kubernetes.** od.**"
<match kubernetes.**> #od.** kubernetes.**>
  @type copy
  <store>
## We store the data in the Elasticsearch instance
    type elasticsearch
    log_level info
    include_tag_key true
    host elasticsearch #"#{ENV['FLUENT_ELASTICSEARCH_HOST']}"
    port 9200 #"#{ENV['FLUENT_ELASTICSEARCH_PORT']}"
    scheme http #"#{ENV['FLUENT_ELASTICSEARCH_SCHEME'] || 'http'}"
    #user "#{ENV['FLUENT_ELASTICSEARCH_USER']}"
    #password "#{ENV['FLUENT_ELASTICSEARCH_PASSWORD']}"
    reload_connections true #"#{ENV['FLUENT_ELASTICSEARCH_RELOAD_CONNECTIONS'] || 'true'}"
    logstash_prefix logstash #"#{ENV['FLUENT_ELASTICSEARCH_LOGSTASH_PREFIX'] || 'logstash'}"
    logstash_format true
    buffer_chunk_limit 2M
    buffer_queue_limit 32
    flush_interval 5s
    max_retry_wait 30
    disable_retry_limit
    num_threads 8
  </store>
  <store>
    @type stdout
  </store>
</match>
</label>
